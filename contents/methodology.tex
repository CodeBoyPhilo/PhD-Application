\section*{Methodologies and Contributions}

To answer our formulated research questions and achieve our research objectives, we plan to conduct the research in the following steps:

\textbf{Survey on KG-augmented LLM generation methods. } 
We will continue to survey the existing and emerging literature that leverages KGs in LLM adaptation to build a thorough understanding of the task. 
In addition, we will explore the availability of domain-specific KGs and datasets that can be used for evaluation in our research.

\textbf{Methodology formulation.}
We will develop novel learning frameworks that can jointly learn knowledge representations from both KGs and LLMs.
%embeds a question-relevant subgraph into informative knowledge features, prevserving only useful knowledge while filtering out superfluous information. 
In addition, we will investigate information theory based multi-modal fusion algorithms that bridge the gap between the graph and text modality to facilitate the interaction and fusion of two heterogeneous representation spaces. 
In a nut shell, our research aims to make methodological contributions by developing novel learning frameworks for KG-augmented LLM adaptation. 

\textbf{Evaluation on domain-specific datasets. } 
We will evaluate our proposed methods on domain-specific datasets and compare with baseline methods, beginning with the biomedical datasets including MedQA-USMLE~\parencite{medqa} and PubMedQA~\parencite{pubmedqa}.
Through evaluation, our research aims to contribute timely new knowledge to the field by investigating how our proposed methods can generalise to various domains as well as analyse their strengths and limitations. 

\textbf{Assessment of the reliance on training data and generalisation to different LLM architectures. }
As our proposed research aims to adapt open-source LLMs to a specific domain only using a limited number of labelled data, we will design controlled experiments to evaluate model performance with varying amounts of labelled data. Our experiments will also extend to assessing the flexibility of our framework across various LLM backbones.

%complement existing methods by achieving a lower reliance on the amounts of labeled training data used and a higher flexibility for adapting open-source LLMs to a specific domain.

