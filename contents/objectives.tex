\section*{Research Questions}

At a higher level, this research aims to leverage domain-specific KGs to address the challenges of LLM hallucination and lack of specialised knowledge, with the ultimate goal of improving the LLM's performance in domain-specific question-answering tasks.

However, real-world KGs are often vast in scale, making it computationally inapplicable to use an entire KG to augment the LLM. Moreover, KGs may contain irrelevant or noisy information that could distract the LLM from attending to the question-relevant information thus hurting the performance. Therefore, our research aims to address the first research question:

\textbf{RQ1:} \emph{How can we effectively retrieve question-relevant information from a noisy large-scale Knowledge Graph to augment an LLM?}

Furthermore, structured KGs and text questions naturally reside in two distinct feature spaces, making it difficult for LLMs pre-trained on text data to integrate the structured knowledge from KGs. As such, we aim to develop methods that answer the second research question:

\textbf{RQ2:} \emph{How can we bridge the modality gap between KGs and LLMs to integrate heterogeneous information from KGs into the LLM's representation space?}

Lastly, since domain-specific training data may be limited due to high annotation costs, our research aims to address the third research question:

\textbf{RQ3:} \emph{How can a general-purpose LLM be adapted with limited amounts of labelled data to effectively answer domain-specific questions?}

