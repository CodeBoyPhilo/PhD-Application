\section*{Literature Review}

In this section, we first present an overview of the related literature, including Knowledge Graph-based question answering over KGs and LLM domain-specific question answering.

\textbf{Knowledge Graph Based Question Answering. }
To begin, we first define a Knowledge Graph as the following:
\begin{definition}
    \emph{A Knowledge Graph is a set of: $\mathcal G = \set{\mathcal E, \mathcal R, \mathcal T}$, where $\mathcal E$ corresponds to a set of entities (nodes),
    $\mathcal R$ refers to a set of relations (edges) between entities,
    and $\mathcal T$ denotes the set of knowledge triplets: $\mathcal T = \set{(e_h,r,e_t)\in \mathcal E\times \mathcal R\times \mathcal E}$, with $e_h, e_t \in \mathcal E$ denoting the head and tail entities
    and $r\in\mathcal R$ is the relation that connects them.}
\end{definition}

Recent works have explicitly followed an extract-encode-fuse paradigm to tackle KG-based question-answering tasks.
Specifically, they first assume a previously established KG exists and extract a subgraph for a given question via entity linking and pathfinding. 
They further encode the question and the subgraph separately using a pre-trained language model (LM) and a graph encoder such as Graph Neural Networks (GNN) and fuse the two heterogeneous representations to generate the final answer.
For example, QAGNN~\parencite{qagnn} used a Graph Attention Network (GAT)~\parencite{gat} as the graph encoder and defined a context node in the graph structure to store the question context information. 
Through the graph connectivity, the encoder iteratively updates the entity representations by attending to context-relevant neighbouring nodes.
Moreover, GreaseLM and Dragon~\parencite{greaselm, dragon} have further introduced a cross-modal fuser to encourage information exchange between the graph and text modalities. 
In contrast, QAT and GRT~\parencite{qat, grt} proposed to encode the KG on a triplet or path level to preserve the relational information.
Furthermore, to improve the knowledge embedding, FiTs~\parencite{fits} have incorporated a contrastive learning objective to align the graph and LM representations of the same concept. Most of these methods are limited to graph learning at the node level, focusing merely on which concepts are important in facilitating question answering, while overlooking the intrinsic relationships among concepts that are essential for complex reasoning. 

%\hw{However, the above methods are limited in only considering graph learning at a node-level, i.e., the reason on which concepts are important in facilitating QA; while overlooking the importance of knowledge triplet information.}
%\hw{Although QAT and GRT managed to learn knowledge representation at a triplet level, their scope is limited to a single-hop path which fortfeits the potential of multi-hop reasoning required in complex questions.}

\textbf{LLM Domain-Specific Question Answering. }
In domain-specific fine-tuning, existing methods typically focus on injecting domain-specific knowledge into the LLM by updating all or only a subset of model parameters \parencite{pmc-llama, medalpaca, llava-med}. 
Alternatively, external resources augmented methods such as RAG-based approaches typically inject domain knowledge into the input level.
The common focus of these methods is how to extract the correct knowledge from external resources and how to teach the LLM to use this new knowledge effectively~\parencite {knowpat, radit}. 
As a subset of RAG-based methods, KG-augmented methods rely on a domain-specific KG as the knowledge provider.
However, because the information encoded in a graph structure essentially differs from unstructured texts, KG-augmented methods emphasise how to integrate the graph representation into the text modality in a way that the LLM can comprehend. 
For instance, KAPING~\parencite{kalm-prompting} flattens the retrieved subgraph and directly inputs the text attributes of the knowledge triplets to the LLM. GNP~\parencite{gnp} builds on KGQA methods and pools the graph representation learned with GNNs and appends the knowledge embeddings to the question embeddings to form a \emph{soft-prompt} \parencite{prompt-tuning}. Despite these early attempts, such methods remain limited in their ability to selectively fuse relevant structured knowledge from KGs into LLM representation learning. They often struggle with multi-hop reasoning and may fail to fully capture the complex relationships between concepts, which are essential for effective domain-specific question answering. 

%\hw{However, KAPING suffers from high knowledge noise that mislead an LLM to generate incorrect answers by attending to irrelevant information.}
%\hw{Moreover, the graph learning method used in GNP is restricted to homogeneous graph and overlooks the relational information present in a knowledge triplet.}
